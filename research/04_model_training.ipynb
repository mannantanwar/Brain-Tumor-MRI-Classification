{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf491a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6022be68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\2101\\\\OneDrive\\\\Desktop\\\\git\\\\Brain-Tumor-MRI-Classification'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b406d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir : Path\n",
    "    trained_model_path:Path\n",
    "    base_model_path:Path\n",
    "    training_data:Path\n",
    "    param_epochs : int\n",
    "    param_batch_size : int\n",
    "    param_is_augmentation : bool\n",
    "    param_image_size : list\n",
    "    param_learning_rate : float\n",
    "    param_seed : int\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir: Path\n",
    "    checkpoint_model_filepath: Path\n",
    "    tensorboard_root_log_dir: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27be82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainTumorMRIClassification.constants import *\n",
    "from brainTumorMRIClassification.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf\n",
    "from brainTumorMRIClassification import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa906ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath = CONFIG_FILE_PATH,params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_prepare_callbacks_config(self) -> PrepareCallbacksConfig:\n",
    "        config=self.config.prepare_callbacks\n",
    "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
    "        create_directories([Path(model_ckpt_dir), Path(config.tensorboard_root_log_dir)])\n",
    "        \n",
    "        return PrepareCallbacksConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            checkpoint_model_filepath=Path(config.checkpoint_model_filepath),\n",
    "            tensorboard_root_log_dir=Path(config.tensorboard_root_log_dir)\n",
    "        )\n",
    "    \n",
    "    def get_training_config(self)->TrainingConfig:\n",
    "        training=self.config.training\n",
    "        prepare_base_model=self.config.prepare_base_model\n",
    "        params=self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir)\n",
    "        create_directories([Path(training.root_dir)]) \n",
    "\n",
    "        return TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            base_model_path=Path(prepare_base_model.base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            param_epochs=params.EPOCHS,\n",
    "            param_batch_size=params.BATCH_SIZE,\n",
    "            param_is_augmentation=params.AUGMENTATION,\n",
    "            param_image_size=params.IMAGE_SIZE,\n",
    "            param_learning_rate=params.LEARNING_RATE,\n",
    "            param_seed=params.SEED\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55b8a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PrepareCallback:\n",
    "    def __init__(self, config: PrepareCallbacksConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _create_early_stopping(self):\n",
    "        return tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='loss',\n",
    "            min_delta=1e-9,\n",
    "            patience=8,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def _create_reduce_lr(self):\n",
    "        return tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.3,\n",
    "            patience=5,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    def get_all_callbacks(self):\n",
    "        return [\n",
    "            self._create_early_stopping,\n",
    "            self._create_reduce_lr\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc7e787",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.4' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.base_model_path\n",
    "        )\n",
    "        self.model.compile(\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=self.config.param_learning_rate, beta_1=0.869, beta_2=0.995),\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "        train_dir = os.path.join(self.config.training_data, \"Training\")\n",
    "        test_dir = os.path.join(self.config.training_data, \"Testing\")\n",
    "        image_size = self.config.param_image_size\n",
    "        target_size = tuple(image_size[:2])  # Only height and width for flow_from_directory\n",
    "        batch_size = self.config.param_batch_size\n",
    "        SEED = self.config.param_seed\n",
    "        from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "        # Data augmentation and preprocessing for training\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=10,\n",
    "            brightness_range=(0.85, 1.15),\n",
    "            width_shift_range=0.002,\n",
    "            height_shift_range=0.002,\n",
    "            shear_range=12.5,\n",
    "            zoom_range=0,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=False,\n",
    "            fill_mode=\"nearest\"\n",
    "        )\n",
    "        self.train_generator = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=target_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode=\"categorical\",\n",
    "            seed=SEED\n",
    "        )\n",
    "\n",
    "        # No augmentation for test data, just rescaling\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        self.valid_generator = test_datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=target_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode=\"categorical\",\n",
    "            shuffle=False,\n",
    "            seed=SEED\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "        logger.info(f\"Model saved at {path}\")\n",
    "\n",
    "    def train(self, callback_list: list):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        logger.info(\"Training Started\")\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.param_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_data=self.valid_generator,\n",
    "            validation_steps=self.validation_steps,\n",
    "            callbacks=callback_list\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac0c6d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-03 12:26:56,719] : INFO : common : YAML file config\\config.yaml loaded successfully.\n",
      "[2025-09-03 12:26:56,724] : INFO : common : YAML file params.yaml loaded successfully.\n",
      "[2025-09-03 12:26:56,727] : INFO : common : Created directory: artifacts\n",
      "[2025-09-03 12:26:56,729] : INFO : common : Created directory: artifacts\\prepare_callbacks\\checkpoint_dir\n",
      "[2025-09-03 12:26:56,731] : INFO : common : Created directory: artifacts\\prepare_callbacks\\tensorboard_log_dir\n",
      "[2025-09-03 12:26:56,734] : INFO : common : Created directory: artifacts\\training\n",
      "[2025-09-03 12:26:57,287] : WARNING : saving_utils : Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Found 5712 images belonging to 4 classes.\n",
      "Found 1311 images belonging to 4 classes.\n",
      "[2025-09-03 12:26:58,011] : INFO : 763540678 : Training Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2101\\OneDrive\\Desktop\\git\\Brain-Tumor-MRI-Classification\\venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 720ms/step - accuracy: 0.6342 - loss: 0.8040 - val_accuracy: 0.7430 - val_loss: 0.6524 - learning_rate: 0.0010\n",
      "Epoch 2/40\n",
      "\u001b[1m  1/178\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.7812 - loss: 0.4435"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2101\\OneDrive\\Desktop\\git\\Brain-Tumor-MRI-Classification\\venv\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.7812 - loss: 0.4435 - val_accuracy: 0.7289 - val_loss: 0.6896 - learning_rate: 0.0010\n",
      "Epoch 3/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 609ms/step - accuracy: 0.8025 - loss: 0.4854 - val_accuracy: 0.7391 - val_loss: 0.5640 - learning_rate: 0.0010\n",
      "Epoch 4/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.6875 - loss: 0.6276 - val_accuracy: 0.7883 - val_loss: 0.4770 - learning_rate: 0.0010\n",
      "Epoch 5/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 692ms/step - accuracy: 0.8371 - loss: 0.4090 - val_accuracy: 0.8031 - val_loss: 0.5023 - learning_rate: 0.0010\n",
      "Epoch 6/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 0.9688 - loss: 0.2454 - val_accuracy: 0.8094 - val_loss: 0.4874 - learning_rate: 0.0010\n",
      "Epoch 7/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 765ms/step - accuracy: 0.8771 - loss: 0.3275 - val_accuracy: 0.8906 - val_loss: 0.3078 - learning_rate: 0.0010\n",
      "Epoch 8/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.9062 - loss: 0.2303 - val_accuracy: 0.8867 - val_loss: 0.3094 - learning_rate: 0.0010\n",
      "Epoch 9/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 512ms/step - accuracy: 0.9025 - loss: 0.2570 - val_accuracy: 0.9164 - val_loss: 0.2311 - learning_rate: 0.0010\n",
      "Epoch 10/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9375 - loss: 0.1786 - val_accuracy: 0.9195 - val_loss: 0.2404 - learning_rate: 0.0010\n",
      "Epoch 11/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 521ms/step - accuracy: 0.9248 - loss: 0.2045 - val_accuracy: 0.9266 - val_loss: 0.2054 - learning_rate: 0.0010\n",
      "Epoch 12/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0313 - val_accuracy: 0.9266 - val_loss: 0.1982 - learning_rate: 0.0010\n",
      "Epoch 13/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 924ms/step - accuracy: 0.9440 - loss: 0.1641 - val_accuracy: 0.9297 - val_loss: 0.1899 - learning_rate: 0.0010\n",
      "Epoch 14/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.9375 - loss: 0.1732 - val_accuracy: 0.9141 - val_loss: 0.2072 - learning_rate: 0.0010\n",
      "Epoch 15/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 895ms/step - accuracy: 0.9477 - loss: 0.1473 - val_accuracy: 0.9312 - val_loss: 0.1933 - learning_rate: 0.0010\n",
      "Epoch 16/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9062 - loss: 0.3553 - val_accuracy: 0.9312 - val_loss: 0.1965 - learning_rate: 0.0010\n",
      "Epoch 17/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 682ms/step - accuracy: 0.9530 - loss: 0.1285 - val_accuracy: 0.9016 - val_loss: 0.3060 - learning_rate: 0.0010\n",
      "Epoch 18/40\n",
      "\u001b[1m  1/178\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 0.0155\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 0.9203 - val_loss: 0.2580 - learning_rate: 0.0010\n",
      "Epoch 19/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 1s/step - accuracy: 0.9771 - loss: 0.0683 - val_accuracy: 0.9734 - val_loss: 0.0922 - learning_rate: 3.0000e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 0.9727 - val_loss: 0.0941 - learning_rate: 3.0000e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 909ms/step - accuracy: 0.9815 - loss: 0.0550 - val_accuracy: 0.9648 - val_loss: 0.1211 - learning_rate: 3.0000e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.9641 - val_loss: 0.1274 - learning_rate: 3.0000e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 845ms/step - accuracy: 0.9831 - loss: 0.0513 - val_accuracy: 0.9742 - val_loss: 0.0913 - learning_rate: 3.0000e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9727 - val_loss: 0.0889 - learning_rate: 3.0000e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 771ms/step - accuracy: 0.9799 - loss: 0.0544 - val_accuracy: 0.9742 - val_loss: 0.0768 - learning_rate: 3.0000e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.9062 - loss: 0.2037 - val_accuracy: 0.9820 - val_loss: 0.0649 - learning_rate: 3.0000e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 796ms/step - accuracy: 0.9833 - loss: 0.0437 - val_accuracy: 0.9750 - val_loss: 0.0885 - learning_rate: 3.0000e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0770 - val_accuracy: 0.9758 - val_loss: 0.0855 - learning_rate: 3.0000e-04\n",
      "Epoch 29/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 763ms/step - accuracy: 0.9840 - loss: 0.0459 - val_accuracy: 0.9836 - val_loss: 0.0675 - learning_rate: 3.0000e-04\n",
      "Epoch 30/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9375 - loss: 0.0485 - val_accuracy: 0.9836 - val_loss: 0.0664 - learning_rate: 3.0000e-04\n",
      "Epoch 31/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781ms/step - accuracy: 0.9916 - loss: 0.0374\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 827ms/step - accuracy: 0.9898 - loss: 0.0345 - val_accuracy: 0.9797 - val_loss: 0.0665 - learning_rate: 3.0000e-04\n",
      "Epoch 32/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.9797 - val_loss: 0.0679 - learning_rate: 9.0000e-05\n",
      "Epoch 32: early stopping\n",
      "[2025-09-03 13:05:33,745] : WARNING : saving_api : You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "[2025-09-03 13:05:34,211] : INFO : 763540678 : Model saved at artifacts\\training\\brain_model.h5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config=ConfigurationManager()\n",
    "    prepare_callbacks_config=config.get_prepare_callbacks_config()\n",
    "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "    callbacks_list = prepare_callbacks.get_all_callbacks()\n",
    "\n",
    "    training_config=config.get_training_config()\n",
    "    training=Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train(callback_list=callbacks_list)\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ddbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
